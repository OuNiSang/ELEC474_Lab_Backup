{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC474 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from cv2 import Stitcher\n",
    "from matplotlib import pyplot as plt\n",
    "from imutils.perspective import four_point_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "global my_SIFT_instance, my_BF_instance\n",
    "my_SIFT_instance = cv.SIFT_create()\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0 #heard from C++ api that this should be 1\n",
    "# FLANN_INDEX_KDTREE = 1\n",
    "\n",
    "dirName1 = 'office2'\n",
    "dirName2 = 'StJames'\n",
    "dirName3 = 'WLH'\n",
    "\n",
    "imgDescipt_1 = np.array((\n",
    "\"Left Key Point\",\n",
    "\"Right Key Points\"\n",
    "))\n",
    "\n",
    "imgDescipt_2 = np.array((\n",
    "\"Select point Output\",\n",
    "\"Epipolar Line Output\"\n",
    "))\n",
    "\n",
    "Process_BarLength = 30\n",
    "\n",
    "BEST_MATCH_METRIC = 300 #StJames is 85, office2 is 200, WLH is 100\n",
    "LOWE_RATIO = 0.7\n",
    "SEED_IDX = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatcheClass:\n",
    "    \"\"\"[summary]\n",
    "    \\nThis Class is used to store and transfer keypoints, descriptors, images between functions\n",
    "    \"\"\"\n",
    "    def __init__(self, kp, des):\n",
    "        self.kp = kp\n",
    "        self.des = des\n",
    "    \n",
    "    def LoadMatch(self, match):\n",
    "        self.matchs = match\n",
    "    \n",
    "    def LoadImg(self, img):\n",
    "        self.img = img\n",
    "    \n",
    "    def __eq__(self, other) -> bool:\n",
    "        return self.__dict__ == other.__dict__\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PltImg(img,imgDescipt):\n",
    "    \"\"\"\n",
    "    \\nTake in a img list and a img descriptions to do plt.imshow in a window\n",
    "    \\nWith dip == 300 and size zoom (15,15)\n",
    "    Args:\n",
    "        img ([list]): Remember put a single img in list e.g. PltImg([img], [\"Description\"])\n",
    "        imgDescipt ([List]): List of String to descripe each img\n",
    "    \"\"\"\n",
    "    plt.figure(dpi=300)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    idx = len(img)\n",
    "    for i in range(idx):\n",
    "        plt.subplot(1,idx,i+1)\n",
    "\n",
    "        if(len(img[i].shape) == 2): #differ from gray and color img \n",
    "            plt.imshow(img[i],cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(cv.cvtColor(img[i], cv.COLOR_BGR2RGB))\n",
    "\n",
    "        plt.title(imgDescipt[i])\n",
    "    plt.tight_layout()\n",
    "\n",
    "def ReadImgs(dirName, imgName):\n",
    "    \"\"\"\n",
    "    \\nFetching images based on given directory and return it \n",
    "    Args:\n",
    "        dirName (string): name of dir \n",
    "        imgName (string): name of img]\n",
    "    \"\"\"\n",
    "    return cv.imread(os.getcwd()+'//'+dirName+'//'+imgName)\n",
    "\n",
    "def FetchingImgs(dirName):\n",
    "    \"\"\"Fetching Imgs based on given file name\n",
    "    \\n Remember the file should be in the same dir with this script \n",
    "    Args:\n",
    "        dirName (string): Name of the file\n",
    "\n",
    "    Returns:\n",
    "        [List]: a list of imgs\n",
    "    \"\"\"\n",
    "    #list all the img file under dir \n",
    "    ls = []\n",
    "    dir = os.getcwd()+'//'+dirName\n",
    "    files = os.listdir(dir)\n",
    "    for filename in files:\n",
    "        # print(dir + os.sep + filename)\n",
    "\n",
    "        if os.path.splitext(filename)[1] == '.jpg':\n",
    "            ls.append(filename)\n",
    "    if ls.count != 0:\n",
    "        print(\"Detected\", len(ls),\"Images\")\n",
    "    return ls\n",
    "\n",
    "def ProgressionBarUpdate(current,overall):\n",
    "    \"\"\"\\n Tools used to show update by a progression \n",
    "    Args:\n",
    "        current (int): current progress\n",
    "        overall (int): total progress\n",
    "    \"\"\"\n",
    "    pctge = (current+1) / overall\n",
    "    if pctge > 1:\n",
    "        pctge = 1\n",
    "    temp = int(round(Process_BarLength * pctge))\n",
    "    print('\\r%s%s%s%s'% ((temp)*'█',(Process_BarLength-temp)*'░',str(round(pctge*100)),'%'), end = ' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching function class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindDescriptorAndKeyPoints(img,descriptor,flag):\n",
    "    \"\"\"find key points and descriptors based on given imgs and descriptor instance\n",
    "    Args:\n",
    "        flag ([int]): when img is BGR image, set flag to 1, if gray set to 0\n",
    "    Returns:\n",
    "        [MatcheCLass]\n",
    "    \"\"\"\n",
    "    \n",
    "    imgGray = img\n",
    "    if flag == 1:\n",
    "        imgGray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    kp, des = descriptor.detectAndCompute(imgGray,None)\n",
    "    return MatcheClass(kp, des)\n",
    "\n",
    "def FlannBasedMatchLoweRatio(descriptor1,descriptor2,   \n",
    "                            flann_Instance,\n",
    "                            kNum = 2, ratio = 0.7):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        kNum (int, optional): [description]. Defaults to 2.\n",
    "        ratio (float, optional): [description]. Defaults to 0.7.\n",
    "\n",
    "    Returns:\n",
    "        [Match]\n",
    "    \"\"\"\n",
    "    \n",
    "    matches = flann_Instance.knnMatch(descriptor1,descriptor2,k = kNum)\n",
    "\n",
    "    loweMatch = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            loweMatch.append(m)\n",
    "    return loweMatch\n",
    "\n",
    "def Matching(img1, img2, descriptor = my_SIFT_instance, loweRatio = LOWE_RATIO):\n",
    "    \"\"\"[summary]\n",
    "    With given 2 imgs return there kps des, and matchs  \n",
    "    Args:\n",
    "\n",
    "        descriptor ([type], optional): Defaults to my_SIFT_instance.\n",
    "        loweRatio ([type], optional):Defaults to LOWE_RATIO.\n",
    "\n",
    "    Returns:\n",
    "        [MatcheClass]: with only kp and des inside, usally for seed img\n",
    "        [MatcheClass]: with all inside and their matchs\n",
    "    \"\"\"\n",
    "    \n",
    "    #FLANN para and create\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)       #or pass empty dict #It specifies the number of times the trees in the index should be recursively traversed.\n",
    "    flann_Instance = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    \n",
    "    #Find img is colored or gray scale\n",
    "    flag = 0\n",
    "    if(len(img1.shape) == 3):\n",
    "        flag = 1\n",
    "    \n",
    "    kpDes_1 = FindDescriptorAndKeyPoints(img1, descriptor, flag)\n",
    "    kpDes_2 = FindDescriptorAndKeyPoints(img2, descriptor, flag) \n",
    "    matches = FlannBasedMatchLoweRatio(kpDes_1.des, kpDes_2.des,\n",
    "                            flann_Instance,\n",
    "                            kNum = 2, ratio = loweRatio)  #NOTE: The ratio difference of lowe will result in different epiploar lines \n",
    "    \n",
    "    kpDes_2.LoadMatch(matches)\n",
    "    kpDes_2.LoadImg(img2)\n",
    "    return kpDes_1, kpDes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MatchingFeaturesOfImages(dirName, descriptorMethod = 'sift'):\n",
    "    \"\"\"[summary]\n",
    "    \\nWith given directory name, \\nFetching imgs and find the best imgs with given seed img and good match imgs\n",
    "    Which control by SEED_IDX and BEST_MATCH_METRIC\\n\n",
    "    Args:\n",
    "        dirName (string): name of the file with all imgs inside, BESURE it is in the same dir with this script\n",
    "        descriptorMethod (str, optional):Can use sift, surf and brisk. Defaults to 'sift'.\n",
    "\n",
    "    Returns:\n",
    "        [MatcheClass]: seed MatcheClassimg\n",
    "        [MatcheClass List]: good match MatcheClass lists \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    idx = 0\n",
    "    numGoodMatch = 0\n",
    "    imgList = []\n",
    "    matchList = []\n",
    "\n",
    "    # detect and extract features from the image\n",
    "    if descriptorMethod == 'sift':\n",
    "        descriptor = cv.xfeatures2d.SIFT_create()\n",
    "    elif descriptorMethod == 'surf':\n",
    "        descriptor = cv.xfeatures2d.SURF_create()\n",
    "    elif descriptorMethod == 'brisk':\n",
    "        descriptor = cv.BRISK_create()\n",
    "    \n",
    "    print(\"Featching Images under Dir and creating descriptors for them\")\n",
    "    imgNameList = FetchingImgs(dirName)\n",
    "    for imgName in imgNameList:\n",
    "        idx += 1\n",
    "        ProgressionBarUpdate(idx, len(imgNameList)+1)\n",
    "        \n",
    "        temp = ReadImgs(dirName, imgName)\n",
    "        imgList.append(temp)\n",
    "        \n",
    "\n",
    "    seedIdx = SEED_IDX\n",
    "    seedImg = imgList[seedIdx]\n",
    "    print(\"\\nYour Seed Idex from Imgaes is\", SEED_IDX, \"And Your Seed Image Looks like:\")\n",
    "    PltImg([seedImg],[\"Seed Image\"])\n",
    "    \n",
    "    print(\"\\nFinding best Match for each pair of imgs\")\n",
    "    imgListIdx = list(range(len(imgList)))\n",
    "    imgListIdx.remove(seedIdx)\n",
    "    for imgIdx in imgListIdx:\n",
    "        ProgressionBarUpdate(imgIdx+1,len(imgList)-1)\n",
    "        seedPara,compare = Matching(seedImg, imgList[imgIdx],descriptor)\n",
    "        if len(compare.matchs) > BEST_MATCH_METRIC:\n",
    "            matchList.append(compare)\n",
    "            numGoodMatch += 1\n",
    "    seedPara.LoadImg(seedImg)\n",
    "            \n",
    "    \n",
    "    print(\"\\nThere are\", numGoodMatch, \"good Image Pairs has been find\")\n",
    "        \n",
    "    return seedPara,matchList\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLListClasification(mList:MatcheClass, seedPara:MatcheClass):\n",
    "    \"\"\"[summary]\n",
    "    Divde imgs into right and left imgs based on seed imgs\n",
    "    Args:\n",
    "        mList (MatcheClass): list of good match MatcheClass\n",
    "        seedPara (MatcheClass): seed img's MatcheClass\n",
    "\n",
    "    Returns:\n",
    "        [list]: list of MatcheClass belongs to LEFT  side of seed \n",
    "        [list]: list of MatcheClass belongs to RIGHT side of seed \n",
    "    \"\"\"\n",
    "    \n",
    "    leftList = []\n",
    "    rightList = []\n",
    "    for currentPair in mList:\n",
    "        \n",
    "        height_src, width_src = seedPara.img.shape[:2]\n",
    "        H = FindHomographic(seedPara.kp, currentPair.kp,currentPair.matchs)\n",
    "        pts = np.float32(\n",
    "        [[0, 0], [0, height_src], [width_src, height_src], [width_src, 0]]\n",
    "        ).reshape(-1, 1, 2)\n",
    "        direction = cv.perspectiveTransform(pts, H)\n",
    "        \n",
    "        if direction[0][0][0] < 0: \n",
    "            # print(\"is Left Image\")\n",
    "            # PltImg([seedImg, cmprImg], [\"L compare\", \"L source\"])\n",
    "            leftList.append(currentPair)\n",
    "        else:\n",
    "            # print(\"is Right Imgae\")\n",
    "            rightList.append(currentPair)\n",
    "            # PltImg([seedImg, cmprImg], [\"R compare\", \"R source\"]\n",
    "            \n",
    "    #Sort from large matchs to low matches\n",
    "    leftList.sort(key = lambda para:len(para.matchs), reverse=False) \n",
    "    rightList.sort(key = lambda para:len(para.matchs), reverse=True) \n",
    "    return leftList, rightList\n",
    "\n",
    "def FindHomographic(kp1, kp2, match):\n",
    "    \"\"\"[summary]\n",
    "    \\nReturn H matrix based on given kypoints\n",
    "    \"\"\"\n",
    "    ref_pts = np.float32([kp1[m.queryIdx].pt for m in match]).reshape(-1,1,2)\n",
    "    img_pts = np.float32([kp2[m.trainIdx].pt for m in match]).reshape(-1,1,2)\n",
    "\n",
    "    H, _ = cv.findHomography(ref_pts, img_pts, cv.RANSAC, 5)\n",
    "    \n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChopBlackSide(img):\n",
    "    \"\"\"[summary]\n",
    "    \\nBased on given img, chop out the blackside without effective pixels \n",
    "    \"\"\"\n",
    "    \n",
    "    image = img \n",
    "    img = cv.medianBlur(image, 5)\n",
    "    gray_img = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    _, th = cv.threshold(gray_img, 1, 255, cv.THRESH_BINARY)\n",
    "    contour, _ = cv.findContours(th, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = contour[0]\n",
    "    x,y,w,h = cv.boundingRect(cnt)\n",
    "    cropImg = img[y:y+h, x:x+w]\n",
    "    # PltImg([cropImg],\"Chop\")\n",
    "    return cropImg\n",
    "\n",
    "def StichImgesPair(imgMain, imgWarp):\n",
    "    \"\"\"[summary]\n",
    "    \\nWith given 2 imgs return their stich img\n",
    "    Args:\n",
    "        imgMain ([Img]): The img that will be stick back, with no warp at all\n",
    "        imgWarp ([Img]): The img that will be warped and overlay by imgMain\n",
    "    \"\"\"\n",
    "    warpBuffer = [imgMain.shape[1] + imgWarp.shape[1], imgMain.shape[0]+imgWarp.shape[0]]\n",
    "    img1Para, img2Para = Matching(imgMain, imgWarp)\n",
    "    H = FindHomographic(img1Para.kp, img2Para.kp,img2Para.matchs)\n",
    "    H = np.linalg.inv(H)\n",
    "    \n",
    "    warpImg = cv.warpPerspective(imgWarp, H, warpBuffer)\n",
    "    warpImg[0:imgMain.shape[0], 0:imgMain.shape[1]] = imgMain\n",
    "    warpImg = ChopBlackSide(warpImg)\n",
    "    PltImg([warpImg, imgMain, imgWarp], [\"Warped\", \"Source\", \"Append\"]) #Uncomment this to see by steps\n",
    "    \n",
    "    return warpImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalRefine(img, offset):\n",
    "    \"\"\"[summary]\n",
    "    \\nThe raw result has many deformation, based on raw return a better result\n",
    "    Args:\n",
    "        offset (int): Usually be the original img height\n",
    "    \"\"\"\n",
    "    height,width = img.shape[:2]\n",
    "    top_left = [0,0]\n",
    "    o_top_right = [width, 0]\n",
    "    bottom_right = [width,height]\n",
    "    bottom_left = [0,offset]\n",
    "    point = np.array((top_left, bottom_left, o_top_right, bottom_right),dtype = \"float32\")\n",
    "    img = four_point_transform(img, point)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StichImgMainFunc(dirName):\n",
    "    \"\"\"[summary]\n",
    "    \\nThe Main fucntion for this script, with given folder name Plt the stich imgs\n",
    "    Args:\n",
    "        dirName ([string]): img folder name\n",
    "    \"\"\"\n",
    "    print(\"Start Fetching images under Dir\", dirName)\n",
    "    seedPara, mList = MatchingFeaturesOfImages(dirName)\n",
    "    print(\"Classify Images into Left And Right based on Seed Image\")\n",
    "    leftList, rightList = RLListClasification(mList, seedPara)\n",
    "\n",
    "    print(\"Start Stiching Imgs together\")\n",
    "    warpComb = StichImgesPair(leftList[0].img, seedPara.img)\n",
    "    print(\"Start Stiching With Left pairs ....\")\n",
    "    idx = 0\n",
    "    for currentLeft in leftList[1:]:\n",
    "        idx += 1\n",
    "        ProgressionBarUpdate(idx,len(leftList))\n",
    "        warpComb = StichImgesPair(currentLeft.img, warpComb) \n",
    "    print(\"\\nCalabrating ......\")\n",
    "    warpComb = FinalRefine(warpComb, seedPara.img.shape[0])\n",
    "    # PltImg([warpComb], [\"Check\"])\n",
    "    print(\"\\nStart Stiching With Right pairs ....\")\n",
    "    idx = 0\n",
    "    for currentRight in rightList[:]:\n",
    "        idx += 1\n",
    "        ProgressionBarUpdate(idx,len(rightList))\n",
    "        warpComb = StichImgesPair(currentRight.img,warpComb)\n",
    "        # print(\"\\nCalabrating ......\")\n",
    "        # warpComb = FinalRefine(warpComb, seedPara.img.shape[0])\n",
    "    PltImg([warpComb], [\"Raw Result\"])\n",
    "    print(\"\\nStart Final Calabration\")\n",
    "    warpComb = FinalRefine(warpComb, seedPara.img.shape[0])\n",
    "    \n",
    "    print(\"!!!!!FINISH!!!!!\")\n",
    "    PltImg([warpComb], [\"FINAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fetching images under Dir StJames\n",
      "Featching Images under Dir and creating descriptors for them\n",
      "Detected 16 Images\n",
      "██████████████████████████████100% \n",
      "Your Seed Idex from Imgaes is 14 And Your Seed Image Looks like:\n",
      "\n",
      "Finding best Match for each pair of imgs\n",
      "██████░░░░░░░░░░░░░░░░░░░░░░░░20% "
     ]
    }
   ],
   "source": [
    "StichImgMainFunc(dirName2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b056a9bb4571a21e1bea1a08acdc3037d3766ff6fcbe41686b1e6c449717e736"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
